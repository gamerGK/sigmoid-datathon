{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport string\nimport json\nimport emoji\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option(\"display.max_columns\", None)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:25.016507Z","iopub.execute_input":"2022-11-04T20:57:25.016860Z","iopub.status.idle":"2022-11-04T20:57:25.022934Z","shell.execute_reply.started":"2022-11-04T20:57:25.016828Z","shell.execute_reply":"2022-11-04T20:57:25.021678Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# df_train = pd.read_csv(\"../input/emotion-data/emotion_data/train.csv\")\n# # df_train.head()\n\n# # df_train = pd.read_csv(\"../input/emotion-data/goemotion.csv\")\n# df_test = pd.read_csv(\"../input/emotion-data/emotion_data/test.csv\")\n# # df_valid = pd.read_csv(\"../input/emotion-data/emotion_data/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:25.434126Z","iopub.execute_input":"2022-11-04T20:57:25.434546Z","iopub.status.idle":"2022-11-04T20:57:25.438792Z","shell.execute_reply.started":"2022-11-04T20:57:25.434507Z","shell.execute_reply":"2022-11-04T20:57:25.437904Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/voilla/additional_features_train.csv\", index_col=[\"Unnamed: 0\"])\ndf_test = pd.read_csv(\"../input/voilla/additional_features_test.csv\", index_col=[\"Unnamed: 0\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:26.267791Z","iopub.execute_input":"2022-11-04T20:57:26.269582Z","iopub.status.idle":"2022-11-04T20:57:26.426351Z","shell.execute_reply.started":"2022-11-04T20:57:26.269527Z","shell.execute_reply":"2022-11-04T20:57:26.425439Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:26.523911Z","iopub.execute_input":"2022-11-04T20:57:26.524185Z","iopub.status.idle":"2022-11-04T20:57:26.530251Z","shell.execute_reply.started":"2022-11-04T20:57:26.524157Z","shell.execute_reply":"2022-11-04T20:57:26.529082Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(7724, 21)"},"metadata":{}}]},{"cell_type":"code","source":"import json","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:26.789215Z","iopub.execute_input":"2022-11-04T20:57:26.789496Z","iopub.status.idle":"2022-11-04T20:57:26.793370Z","shell.execute_reply.started":"2022-11-04T20:57:26.789467Z","shell.execute_reply":"2022-11-04T20:57:26.792495Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"df_train[\"encoded_dependency_features\"] = df_train[\"encoded_dependency_features\"].apply(json.loads)\ndf_train[\"encoded_noun_features\"] = df_train[\"encoded_noun_features\"].apply(json.loads)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:27.068469Z","iopub.execute_input":"2022-11-04T20:57:27.069027Z","iopub.status.idle":"2022-11-04T20:57:27.251474Z","shell.execute_reply.started":"2022-11-04T20:57:27.068967Z","shell.execute_reply":"2022-11-04T20:57:27.250565Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# type(.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:27.309845Z","iopub.execute_input":"2022-11-04T20:57:27.310153Z","iopub.status.idle":"2022-11-04T20:57:27.315264Z","shell.execute_reply.started":"2022-11-04T20:57:27.310124Z","shell.execute_reply":"2022-11-04T20:57:27.314071Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_dev = df_train.iloc[:1000]\ndf_train = df_train.iloc[1000:]","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:28.285304Z","iopub.execute_input":"2022-11-04T20:57:28.285671Z","iopub.status.idle":"2022-11-04T20:57:28.290756Z","shell.execute_reply.started":"2022-11-04T20:57:28.285621Z","shell.execute_reply":"2022-11-04T20:57:28.289648Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.reset_index(drop=True)\ndf_dev = df_dev.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:28.517522Z","iopub.execute_input":"2022-11-04T20:57:28.517822Z","iopub.status.idle":"2022-11-04T20:57:28.524447Z","shell.execute_reply.started":"2022-11-04T20:57:28.517794Z","shell.execute_reply":"2022-11-04T20:57:28.523504Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"print(df_train.shape)\nprint(df_dev.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:28.777839Z","iopub.execute_input":"2022-11-04T20:57:28.778110Z","iopub.status.idle":"2022-11-04T20:57:28.784345Z","shell.execute_reply.started":"2022-11-04T20:57:28.778083Z","shell.execute_reply":"2022-11-04T20:57:28.783509Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"(6724, 21)\n(1000, 21)\n","output_type":"stream"}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:29.050521Z","iopub.execute_input":"2022-11-04T20:57:29.050860Z","iopub.status.idle":"2022-11-04T20:57:29.055263Z","shell.execute_reply.started":"2022-11-04T20:57:29.050830Z","shell.execute_reply":"2022-11-04T20:57:29.054264Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Sections of config\n\n# Defining some key variables that will be used later on in the training\nMAX_LEN = 150\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 32\nEPOCHS = 10\nLEARNING_RATE = 2e-5\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:29.381604Z","iopub.execute_input":"2022-11-04T20:57:29.381902Z","iopub.status.idle":"2022-11-04T20:57:35.696020Z","shell.execute_reply.started":"2022-11-04T20:57:29.381874Z","shell.execute_reply":"2022-11-04T20:57:35.695151Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/768 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e1ccd959c7240409293d8ddf68cd0d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cadce36f22f43598fec5f470e5a8f84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b88b26e5634b219a23ec62780a890f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e339e676b16640da80abeff226f31757"}},"metadata":{}}]},{"cell_type":"code","source":"# df_train","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:35.698011Z","iopub.execute_input":"2022-11-04T20:57:35.698368Z","iopub.status.idle":"2022-11-04T20:57:35.703373Z","shell.execute_reply.started":"2022-11-04T20:57:35.698330Z","shell.execute_reply":"2022-11-04T20:57:35.702273Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"target_cols = [ 'anger', 'anticipation', 'disgust', 'fear', 'joy',\n       'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust', 'neutral']\ntarget_cols","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:35.704892Z","iopub.execute_input":"2022-11-04T20:57:35.705441Z","iopub.status.idle":"2022-11-04T20:57:35.714848Z","shell.execute_reply.started":"2022-11-04T20:57:35.705404Z","shell.execute_reply":"2022-11-04T20:57:35.713977Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"['anger',\n 'anticipation',\n 'disgust',\n 'fear',\n 'joy',\n 'love',\n 'optimism',\n 'pessimism',\n 'sadness',\n 'surprise',\n 'trust',\n 'neutral']"},"metadata":{}}]},{"cell_type":"code","source":"class BERTDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.text = df.Tweet\n        self.tokenizer = tokenizer\n        self.targets = df[target_cols].values\n        self.feature1 = df[\"encoded_dependency_features\"]\n        self.feature2 = df[\"encoded_noun_features\"]\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'feature1' : torch.tensor(self.feature1[index], dtype=torch.long),\n            'feature2' : torch.tensor(self.feature2[index], dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:35.716586Z","iopub.execute_input":"2022-11-04T20:57:35.716940Z","iopub.status.idle":"2022-11-04T20:57:35.726373Z","shell.execute_reply.started":"2022-11-04T20:57:35.716900Z","shell.execute_reply":"2022-11-04T20:57:35.725445Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"train_dataset = BERTDataset(df_train, tokenizer, MAX_LEN)\nvalid_dataset = BERTDataset(df_dev, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:35.729597Z","iopub.execute_input":"2022-11-04T20:57:35.729861Z","iopub.status.idle":"2022-11-04T20:57:35.742132Z","shell.execute_reply.started":"2022-11-04T20:57:35.729834Z","shell.execute_reply":"2022-11-04T20:57:35.741327Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, \n                          num_workers=4, shuffle=True, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE, \n                          num_workers=4, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:35.744087Z","iopub.execute_input":"2022-11-04T20:57:35.744428Z","iopub.status.idle":"2022-11-04T20:57:35.781264Z","shell.execute_reply.started":"2022-11-04T20:57:35.744393Z","shell.execute_reply":"2022-11-04T20:57:35.780359Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel\n_model = AutoModel.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n# sentence-transformers/all-MiniLM-L6-v2","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:35.782371Z","iopub.execute_input":"2022-11-04T20:57:35.782733Z","iopub.status.idle":"2022-11-04T20:57:53.477680Z","shell.execute_reply.started":"2022-11-04T20:57:35.782698Z","shell.execute_reply":"2022-11-04T20:57:53.476901Z"},"trusted":true},"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87af1e6e201d44a297892193a362ce4b"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# _model","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:53.479728Z","iopub.execute_input":"2022-11-04T20:57:53.480323Z","iopub.status.idle":"2022-11-04T20:57:53.487580Z","shell.execute_reply.started":"2022-11-04T20:57:53.480283Z","shell.execute_reply":"2022-11-04T20:57:53.483898Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# from torch import nn\n# _model.classifier.out_proj = torch.nn.Linear(in_features=768, out_features=11, bias=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:53.488912Z","iopub.execute_input":"2022-11-04T20:57:53.489264Z","iopub.status.idle":"2022-11-04T20:57:55.249616Z","shell.execute_reply.started":"2022-11-04T20:57:53.489231Z","shell.execute_reply":"2022-11-04T20:57:55.248508Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# _model","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.251509Z","iopub.execute_input":"2022-11-04T20:57:55.252165Z","iopub.status.idle":"2022-11-04T20:57:55.260311Z","shell.execute_reply.started":"2022-11-04T20:57:55.252126Z","shell.execute_reply":"2022-11-04T20:57:55.259387Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from torch import nn","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.261596Z","iopub.execute_input":"2022-11-04T20:57:55.262008Z","iopub.status.idle":"2022-11-04T20:57:55.270924Z","shell.execute_reply.started":"2022-11-04T20:57:55.261972Z","shell.execute_reply":"2022-11-04T20:57:55.270089Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n\nclass BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.roberta = _model\n        self.dense_layer_1 = nn.Linear(768+110+110, 256)\n        self.dropout = nn.Dropout(0.2)\n        self.dense_layer_2 = nn.Linear(256, 128)\n        self.dropout_2 = nn.Dropout(0.2) \n        self.cls_layer = nn.Linear(128, 12, bias = True)\n    \n    def forward(self, input_ids, attention_masks, feature1, feature2):\n        \n        pooled_output = self.roberta(input_ids=input_ids, attention_mask=attention_masks)[\"pooler_output\"]\n        \n        concat = torch.cat( (pooled_output, feature1, feature2), dim=1 )\n        \n        x = self.dense_layer_1(concat)\n        x = self.dropout(x)\n        x_1 = self.dense_layer_2(x)\n        x_2 = self.dropout_2(x_1)\n        \n        logits = self.cls_layer(x_2)\n        \n        return logits\n\nmodel = BERTClass()\nmodel.to(device);","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.272110Z","iopub.execute_input":"2022-11-04T20:57:55.272474Z","iopub.status.idle":"2022-11-04T20:57:55.420878Z","shell.execute_reply.started":"2022-11-04T20:57:55.272430Z","shell.execute_reply":"2022-11-04T20:57:55.420068Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class ContrastiveLoss(torch.nn.Module):\n  def __init__(self, m=2.0):\n    super(ContrastiveLoss, self).__init__()  # pre 3.3 syntax\n    self.m = m  # margin or radius\n\n  def forward(self, y1, y2, d=0):\n    # d = 0 means y1 and y2 are supposed to be same\n    # d = 1 means y1 and y2 are supposed to be different\n    \n    euc_dist = torch.nn.functional.pairwise_distance(y1, y2)\n\n    if d == 0:\n      return torch.mean(torch.pow(euc_dist, 2))  # distance squared\n    else:  # d == 1\n      delta = self.m - euc_dist  # sort of reverse distance\n      delta = torch.clamp(delta, min=0.0, max=None)\n      return torch.mean(torch.pow(delta, 2))  # mean over all rows\n\nloss_fn = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.422405Z","iopub.execute_input":"2022-11-04T20:57:55.422797Z","iopub.status.idle":"2022-11-04T20:57:55.429648Z","shell.execute_reply.started":"2022-11-04T20:57:55.422760Z","shell.execute_reply":"2022-11-04T20:57:55.428720Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"from torch.optim import Adam","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.431512Z","iopub.execute_input":"2022-11-04T20:57:55.431860Z","iopub.status.idle":"2022-11-04T20:57:55.439355Z","shell.execute_reply.started":"2022-11-04T20:57:55.431827Z","shell.execute_reply":"2022-11-04T20:57:55.438486Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(params =  model.parameters(), betas=(0.9, 0.999), eps=1e-8, lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.442333Z","iopub.execute_input":"2022-11-04T20:57:55.442715Z","iopub.status.idle":"2022-11-04T20:57:55.452262Z","shell.execute_reply.started":"2022-11-04T20:57:55.442678Z","shell.execute_reply":"2022-11-04T20:57:55.451386Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def validation():\n    model.eval()\n    fin_targets=[]\n    fin_outputs=[]\n    with torch.no_grad():\n        for _, data in enumerate(valid_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            feature1 = data['feature1'].to(device, dtype = torch.long)\n            feature2 = data['feature2'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, feature1, feature2)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.453884Z","iopub.execute_input":"2022-11-04T20:57:55.454233Z","iopub.status.idle":"2022-11-04T20:57:55.463640Z","shell.execute_reply.started":"2022-11-04T20:57:55.454199Z","shell.execute_reply":"2022-11-04T20:57:55.462732Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    model.train()\n    for _,data in enumerate(train_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        feature1 = data['feature1'].to(device, dtype = torch.long)\n        feature2 = data['feature2'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask, feature1, feature2)\n\n        loss = loss_fn(outputs, targets)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        if _%500 == 0:\n            \n            for _, data in enumerate(valid_loader, 0):\n                ids = data['ids'].to(device, dtype = torch.long)\n                mask = data['mask'].to(device, dtype = torch.long)\n                feature1 = data['feature1'].to(device, dtype = torch.long)\n                feature2 = data['feature2'].to(device, dtype = torch.long)\n                targets = data['targets'].to(device, dtype = torch.float)\n                outputs = model(ids, mask, feature1, feature2)\n                loss = loss_fn(outputs, targets)\n                \n            outputs, targets = validation()\n            accuracy = metrics.f1_score(np.array(targets).round().astype(int), np.array(outputs).round().astype(int), average=\"macro\")\n            print(f'Epoch: {epoch}, Val F1:  {accuracy}')\n            print(f'Epoch: {epoch}, Val Loss:  {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.464898Z","iopub.execute_input":"2022-11-04T20:57:55.465279Z","iopub.status.idle":"2022-11-04T20:57:55.476650Z","shell.execute_reply.started":"2022-11-04T20:57:55.465238Z","shell.execute_reply":"2022-11-04T20:57:55.475749Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"for epoch in range(30):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T20:57:55.479125Z","iopub.execute_input":"2022-11-04T20:57:55.479694Z","iopub.status.idle":"2022-11-04T21:37:24.535316Z","shell.execute_reply.started":"2022-11-04T20:57:55.479638Z","shell.execute_reply":"2022-11-04T21:37:24.533677Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Epoch: 0, Val F1:  0.20682998586230028\nEpoch: 0, Val Loss:  0.7270818948745728\nEpoch: 1, Val F1:  0.3672037594260415\nEpoch: 1, Val Loss:  0.22946123778820038\nEpoch: 2, Val F1:  0.46167119739086054\nEpoch: 2, Val Loss:  0.2265312373638153\nEpoch: 3, Val F1:  0.48834506610580014\nEpoch: 3, Val Loss:  0.20787957310676575\nEpoch: 4, Val F1:  0.4840207266871262\nEpoch: 4, Val Loss:  0.23711282014846802\nEpoch: 5, Val F1:  0.4905962390215013\nEpoch: 5, Val Loss:  0.2221367210149765\nEpoch: 6, Val F1:  0.525532531493519\nEpoch: 6, Val Loss:  0.28976261615753174\nEpoch: 7, Val F1:  0.5383975096721595\nEpoch: 7, Val Loss:  0.315105676651001\nEpoch: 8, Val F1:  0.5483165814138664\nEpoch: 8, Val Loss:  0.27668747305870056\nEpoch: 9, Val F1:  0.549338740835781\nEpoch: 9, Val Loss:  0.3606465756893158\nEpoch: 10, Val F1:  0.5258462928385806\nEpoch: 10, Val Loss:  0.31350183486938477\nEpoch: 11, Val F1:  0.540477624516816\nEpoch: 11, Val Loss:  0.3419830799102783\nEpoch: 12, Val F1:  0.5420873879140685\nEpoch: 12, Val Loss:  0.5443521738052368\nEpoch: 13, Val F1:  0.5407500643908666\nEpoch: 13, Val Loss:  0.4085571765899658\nEpoch: 14, Val F1:  0.5468316893383728\nEpoch: 14, Val Loss:  0.3906698226928711\nEpoch: 15, Val F1:  0.5444310360758141\nEpoch: 15, Val Loss:  0.43810874223709106\nEpoch: 16, Val F1:  0.555424960604609\nEpoch: 16, Val Loss:  0.3749161660671234\nEpoch: 17, Val F1:  0.5373169686142304\nEpoch: 17, Val Loss:  0.44139885902404785\nEpoch: 18, Val F1:  0.5467133580155671\nEpoch: 18, Val Loss:  0.3672386109828949\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-fc22fb0170ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-61-f888628a537d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"outputs, targets = validation()\noutputs = np.array(outputs).round()\n\noutputs = pd.DataFrame(outputs)\n\naccuracy = metrics.accuracy_score(targets, outputs)\nf1_score = metrics.f1_score(targets, outputs, average='macro')\nprint(f\"Accuracy Score = {accuracy}\")\nprint(f\"F1 Score = {f1_score}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-04T21:37:30.020322Z","iopub.execute_input":"2022-11-04T21:37:30.020668Z","iopub.status.idle":"2022-11-04T21:37:35.327247Z","shell.execute_reply.started":"2022-11-04T21:37:30.020625Z","shell.execute_reply":"2022-11-04T21:37:35.326250Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Accuracy Score = 0.227\nF1 Score = 0.5440240917620088\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./hero\"> Download File </a>","metadata":{}},{"cell_type":"code","source":"# test","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:40.951811Z","iopub.execute_input":"2022-10-29T09:30:40.952169Z","iopub.status.idle":"2022-10-29T09:30:40.956899Z","shell.execute_reply.started":"2022-10-29T09:30:40.952140Z","shell.execute_reply":"2022-10-29T09:30:40.956034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, \"hero\")","metadata":{"execution":{"iopub.status.busy":"2022-11-04T21:37:59.276846Z","iopub.execute_input":"2022-11-04T21:37:59.277170Z","iopub.status.idle":"2022-11-04T21:38:00.572964Z","shell.execute_reply.started":"2022-11-04T21:37:59.277141Z","shell.execute_reply":"2022-11-04T21:38:00.572040Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/voilla/additional_features_test.csv\", index_col=[\"Unnamed: 0\"])\ndf_test[\"encoded_dependency_features\"] = df_test[\"encoded_dependency_features\"].apply(json.loads)\ndf_test[\"encoded_noun_features\"] = df_test[\"encoded_noun_features\"].apply(json.loads)","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:40.963121Z","iopub.execute_input":"2022-10-29T09:30:40.963638Z","iopub.status.idle":"2022-10-29T09:30:41.001998Z","shell.execute_reply.started":"2022-10-29T09:30:40.963595Z","shell.execute_reply":"2022-10-29T09:30:41.001244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def give_padding(sent):\n\n  var_len = len(sent)\n  padding_len = 110-var_len\n  padding = [0]*padding_len\n  sent = sent + padding\n  \n  return sent[:110]","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.004870Z","iopub.execute_input":"2022-10-29T09:30:41.005116Z","iopub.status.idle":"2022-10-29T09:30:41.011203Z","shell.execute_reply.started":"2022-10-29T09:30:41.005092Z","shell.execute_reply":"2022-10-29T09:30:41.010387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['encoded_noun_features'] = df_test['encoded_noun_features'].apply(lambda x : give_padding(x) )\ndf_test['encoded_dependency_features'] = df_test['encoded_dependency_features'].apply(lambda x : give_padding(x) )","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.012863Z","iopub.execute_input":"2022-10-29T09:30:41.013202Z","iopub.status.idle":"2022-10-29T09:30:41.022034Z","shell.execute_reply.started":"2022-10-29T09:30:41.013169Z","shell.execute_reply":"2022-10-29T09:30:41.021376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestBERTDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.idx = df.index\n        self.text = df.Tweet\n        self.tokenizer = tokenizer\n        self.feature1 = df[\"encoded_dependency_features\"]\n        self.feature2 = df[\"encoded_noun_features\"]\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        idx = self.idx[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'idx' : torch.tensor(idx, dtype=torch.long),\n            'feature1' : torch.tensor(self.feature1[index], dtype=torch.long),\n            'feature2' : torch.tensor(self.feature2[index], dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.023712Z","iopub.execute_input":"2022-10-29T09:30:41.024193Z","iopub.status.idle":"2022-10-29T09:30:41.034469Z","shell.execute_reply.started":"2022-10-29T09:30:41.024159Z","shell.execute_reply":"2022-10-29T09:30:41.033773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestBERTDataset(df_test, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.037546Z","iopub.execute_input":"2022-10-29T09:30:41.037879Z","iopub.status.idle":"2022-10-29T09:30:41.043803Z","shell.execute_reply.started":"2022-10-29T09:30:41.037853Z","shell.execute_reply":"2022-10-29T09:30:41.043144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=1, \n                          num_workers=4, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.045283Z","iopub.execute_input":"2022-10-29T09:30:41.045779Z","iopub.status.idle":"2022-10-29T09:30:41.057045Z","shell.execute_reply.started":"2022-10-29T09:30:41.045719Z","shell.execute_reply":"2022-10-29T09:30:41.056169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin_outputs=[]\nwith torch.no_grad():\n    for _, data in enumerate(test_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        feature1 = data['feature1'].to(device, dtype = torch.long)\n        feature2 = data['feature2'].to(device, dtype = torch.long)\n        outputs = model(ids, mask, feature1, feature2)\n        fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.058651Z","iopub.execute_input":"2022-10-29T09:30:41.059076Z","iopub.status.idle":"2022-10-29T09:30:41.718444Z","shell.execute_reply.started":"2022-10-29T09:30:41.058967Z","shell.execute_reply":"2022-10-29T09:30:41.716814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fin_outputs","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.719846Z","iopub.status.idle":"2022-10-29T09:30:41.720671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin_outputs = np.array(fin_outputs) >= 0.5","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.721961Z","iopub.status.idle":"2022-10-29T09:30:41.722741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin_outputs.astype(int).sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.723831Z","iopub.status.idle":"2022-10-29T09:30:41.724625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = pd.read_csv(\"../input/emotion-data/emotion_data/train.csv\").columns","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.725768Z","iopub.status.idle":"2022-10-29T09:30:41.726552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.concat([df_test[[\"ID\", \"Tweet\"]], pd.DataFrame(fin_outputs.astype(int))], axis=1)\n# submission[\"neutral\"] = 0\n# submission.columns = columns","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.727649Z","iopub.status.idle":"2022-10-29T09:30:41.728433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.729590Z","iopub.status.idle":"2022-10-29T09:30:41.730379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"optimism.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.731498Z","iopub.status.idle":"2022-10-29T09:30:41.732244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-29T09:30:41.733462Z","iopub.status.idle":"2022-10-29T09:30:41.734296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./model.bin\"> Download File </a>","metadata":{}}]}